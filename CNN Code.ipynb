{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbdb0a3",
   "metadata": {
    "id": "U_nDkagMPv4i"
   },
   "source": [
    "# SVM_NN_CNN_Lithological Mapping Using Satellite Data (ASTER, Landsat, Sentinel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some important and mostly-used packages are already installed on Google-Colab or\n",
    "# You can run the on Jupiter or Spyder environment after installing required packages\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c78179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other packages require installation.\n",
    "# They can be accessed from Github; or installed using \"pip\".\n",
    "\n",
    "# After successful installation, import the package.\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d56944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some packages are very large and you don't need to import the entire library.\n",
    "# Just work with those methods that you'll work through your project.\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1996cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rasterio package to open images.\n",
    "# Data can be read from Google Drive directory.\n",
    "\n",
    "\n",
    "# For LANDSAT\n",
    "LANDSAT = rio.open(r\"D:\\KULIAH\\Makan Bang\\Argopuro\\10. ML\\Code\\CNN\\Dataset\\Virtual Raster.tif\")\n",
    "LANDSAT_array = LANDSAT.read()\n",
    "                   \n",
    "GT = rio.open(r\"D:\\KULIAH\\Makan Bang\\Argopuro\\9.5. Data\\Data 1.0\\Geologi\\Peta Geologi Daerah Penelitian\\Polygon\\Raster Peta Daerah Peneltian.tif\")\n",
    "GT_array = GT.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36685ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDSAT_array.shape\n",
    "GT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11316e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what these datasets look like.\n",
    "print(LANDSAT_array.shape)\n",
    "#print(SENTINEL_array.shape)\n",
    "print(GT_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337e15e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LANDSAT_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nRows \u001b[38;5;241m=\u001b[39m \u001b[43mLANDSAT_array\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m nCols \u001b[38;5;241m=\u001b[39m LANDSAT_array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      3\u001b[0m Bands \u001b[38;5;241m=\u001b[39m LANDSAT_array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LANDSAT_array' is not defined"
     ]
    }
   ],
   "source": [
    "nRows = LANDSAT_array.shape[1]\n",
    "nCols = LANDSAT_array.shape[2]\n",
    "Bands = LANDSAT_array.shape[0]\n",
    "\n",
    "print(Bands,nRows,nCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa1e051",
   "metadata": {
    "id": "bFNN8dWbEASf"
   },
   "source": [
    "## Data Visualization\n",
    "\n",
    "Visualization is the best way to become familiar with your dataset. Also, you can summarize the data by looking at some statistical features of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(LANDSAT_array[2, :, :], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203dbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing DSM\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.imshow(LANDSAT_array[1, :, :], cmap='jet')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d05eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at it's histogram!\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LANDSAT Histogram')\n",
    "n, bins, patches = plt.hist(x=LANDSAT_array.flatten(), bins=100, color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deal with outliers\n",
    "#LANDSAT_array[LANDSAT_array > 60] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07bc18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(LANDSAT_array[0, :, :], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d96b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct for incorrect values (outliers).\n",
    "#LANDSAT_array[LANDSAT_array > 50] = np.nan\n",
    "\n",
    "#plt.figure(figsize=(10, 7))\n",
    "#plt.grid(axis='y', alpha=0.75)\n",
    "#plt.xlabel('Value')\n",
    "#plt.ylabel('Frequency')\n",
    "#plt.title('LANDSAT Histogram')\n",
    "#n, bins, patches = plt.hist(x=LANDSAT_array.flatten(), bins=100, color='r',alpha=0.7, rwidth=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, visualize the corrected data.\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(LANDSAT_array[0, :, :], cmap='jet')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc88ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK. What's next? Ground truth data\n",
    "fig = plt.figure(figsize=(13, 7))\n",
    "gs = fig.add_gridspec(1, 5)\n",
    "fig.add_subplot(gs[0, :3]), plt.imshow(GT_array[0, :, :], cmap='gist_ncar')\n",
    "fig.add_subplot(gs[0, -2:]), plt.imshow(GT_array[0, 200:300, 100:200], cmap='gist_ncar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.unique(GT_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb36ee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GT_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# How many classes?\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mGT_array\u001b[49m[GT_array \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m255\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(GT_array)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(classes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GT_array' is not defined"
     ]
    }
   ],
   "source": [
    "# How many classes?\n",
    "GT_array[GT_array == 255] = 0\n",
    "classes = np.unique(GT_array)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60244b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = 2\n",
    "#cls = np.zeros((nRows, nCols), dtype=int)\n",
    "#cls[GT_array[0, :, :] == c] = 1\n",
    "\n",
    "c = 2\n",
    "cls = np.zeros((nRows, nCols), dtype=int)\n",
    "cls[GT_array[0, :, :] == c] = 1\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at individual classes.\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.tight_layout()\n",
    "for i in range(len(classes)):\n",
    "  if i < 1: \n",
    "    continue\n",
    "  C = np.zeros((nRows, nCols))\n",
    "  C[GT_array[0, :, :] == classes[i]] = 1\n",
    "  plt.subplot(3, 5, i)\n",
    "  plt.title(str(classes[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2cf1c4",
   "metadata": {
    "id": "iP9x3jbAG8cL"
   },
   "source": [
    "## Train/Test Split\n",
    "\n",
    "In order to have completely different and unique train/test samples, we divide our ground truth data into two sets of train samples and test samples.\n",
    "\n",
    "> You can also use [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36592309",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_array = GT_array[0, :, :].astype(int)\n",
    "classes = np.unique(GT_array)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe00172",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GT_array.shape)\n",
    "print(GT_array.flatten().shape)\n",
    "print(nRows * nCols)\n",
    "print(GT_array.flatten()[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "  if i in classes:\n",
    "    print(len(np.where(GT_array.flatten() == i)[0]))\n",
    "\n",
    "# print(len(np.where(GT_array.flatten() == 9)[0]))\n",
    "# print(len(np.where(GT_array.flatten() == 2)[0]))\n",
    "# print(len(np.where(GT_array.flatten() == 4)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_roi(gt_data, percent):\n",
    "  import random\n",
    "\n",
    "  Train = np.zeros_like(gt_data, dtype=int)\n",
    "  Test = np.zeros_like(gt_data, dtype=int)\n",
    "  \n",
    "  labels = list(np.unique(gt_data))\n",
    "  if 0 in labels: labels.remove(0) \n",
    "\n",
    "  for l in labels:\n",
    "    ind = list(np.where(gt_data.flatten() == l)[0])\n",
    "\n",
    "    random.shuffle(ind)\n",
    "    train_inds = ind[:int(percent * len(ind))]\n",
    "    test_inds = ind[int(percent * len(ind)):]\n",
    "\n",
    "    temp = np.zeros((nRows*nCols, 1), dtype=int)\n",
    "    temp[train_inds] = l\n",
    "    temp = temp.reshape((nRows, nCols))\n",
    "    Train = Train + temp\n",
    "    \n",
    "    temp = np.zeros((nRows*nCols, 1), dtype=int)\n",
    "    temp[test_inds] = l\n",
    "    temp = temp.reshape((nRows, nCols))\n",
    "    Test = Test + temp\n",
    "\n",
    "  return Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648fd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = split_roi(GT_array, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121), plt.imshow(Train[400:500, 100:200], cmap='jet')\n",
    "plt.subplot(122), plt.imshow(Test[400:500, 100:200], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a245344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just show a few bands\n",
    "plt.figure(figsize=(13, 13))\n",
    "plt.subplot(321), plt.imshow(LANDSAT_array[0, :, :], cmap='gray')\n",
    "plt.subplot(322), plt.imshow(LANDSAT_array[1, :, :], cmap='gray')\n",
    "plt.subplot(323), plt.imshow(LANDSAT_array[2, :, :], cmap='gray')\n",
    "plt.subplot(324), plt.imshow(LANDSAT_array[3, :, :], cmap='gray')\n",
    "plt.subplot(325), plt.imshow(LANDSAT_array[4, :, :], cmap='gray')\n",
    "plt.subplot(326), plt.imshow(LANDSAT_array[5, :, :], cmap='gray')\n",
    "plt.subplot(326), plt.imshow(LANDSAT_array[6, :, :], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9558b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, we can see the spectral curve of a pixel.\n",
    "plt.plot(LANDSAT_array[:, 200, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(LANDSAT_array[:, Train == c][:, :10], axis=1).shape\n",
    "x = np.mean(LANDSAT_array[:, Train == c][:, :10], axis=1).shape\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try it for a class.\n",
    "classes = [1, 2, 3, 4, 5, 6, 7]\n",
    "plt.figure(figsize=(25, 25))\n",
    "for c in classes:\n",
    "  plt.subplot(7, 2, classes.index(c)+1), plt.plot(LANDSAT_array[:, Train == c][:, :10], 'y')\n",
    "  plt.plot(np.mean(LANDSAT_array[:, Train == c][:, :10], axis=1), 'k')\n",
    "  plt.ylim([0, 400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234ba82",
   "metadata": {
    "id": "znE37xxlG1Cb"
   },
   "source": [
    "## Data Standardization\n",
    "\n",
    "[Standardization](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling) of datasets is to make data look like Gaussian with **zero mean and unit variance**.\n",
    "\n",
    "In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "> We are actually standardizing our datasets.\n",
    "\n",
    "![picture](https://scikit-learn.org/stable/_images/sphx_glr_plot_all_scaling_002.png)\n",
    "\n",
    "[Normalization](https://scikit-learn.org/stable/modules/preprocessing.html#normalization) is the process of scaling individual samples to have **unit norm**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDSAT_array.reshape(7, nRows * nCols).T.shape\n",
    "# [ # observations (# samples / # pixels),  # features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning operation.\n",
    "LANDSAT_data = LANDSAT_array.reshape(7, nRows * nCols).T\n",
    "#SENTINEL_data = SENTINEL_array.reshape(13, nRows * nCols).T\n",
    "\n",
    "Train_data = Train.reshape(1, nRows * nCols).T\n",
    "Test_data = Test.reshape(1, nRows * nCols).T\n",
    "\n",
    "print(LANDSAT_data.shape, Train_data.shape, Test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing data\n",
    "scaler = StandardScaler()\n",
    "LANDSAT_standard = scaler.fit(LANDSAT_data)\n",
    "print(scaler.mean_, scaler.var_)\n",
    "LANDSAT_standard = LANDSAT_standard.transform(LANDSAT_data)\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can do the same operation mannually.\n",
    "# ASTER_standard = np.zeros_like(ASTER_data, dtype=np.float)\n",
    "# for i in range(48):\n",
    "#   ASTER_standard[:, i] = (ASTER_data[:, i] - np.mean(ASTER_data[:, i])) / np.std(ASTER_data[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how standardization works.\n",
    "plt.figure(figsize=(10, 10))\n",
    "for c in classes:\n",
    "  plt.subplot(7, 2, classes.index(c)+1), plt.plot(LANDSAT_standard[Train.flatten() == c, :][:10, :].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ea8e5",
   "metadata": {
    "id": "3JHStCLJPv4z"
   },
   "source": [
    "# Classification-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyrsgis\n",
    "import numpy as np\n",
    "import random\n",
    "# import sklearn\n",
    "from pyrsgis import raster\n",
    "from pyrsgis.ml import imageChipsFromArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rasterio\n",
    "\n",
    "# After successful installation, import the package.\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c966de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASTER = rio.open('E:/My_Flash64/SVM_NN/ASTER_CNN/Input/AST15.tif')\n",
    "#ASTER_array = ASTER.read()\n",
    "\n",
    "#GT = rio.open('E:/My_Flash64/SVM_NN/ASTER_CNN/Input/GT15.tif')\n",
    "#GT_array = GT.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining file names\n",
    "featureFile = r\"D:\\KULIAH\\Makan Bang\\Argopuro\\10. ML\\Code\\CNN\\Dataset\\Virtual Raster.tif\"\n",
    "labelFile = r\"D:\\KULIAH\\Makan Bang\\Argopuro\\9.5. Data\\Data 1.0\\Geologi\\Peta Geologi Daerah Penelitian\\Polygon\\Raster Peta Daerah Peneltian.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1820ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and normalizing input data\n",
    "dsFeatures, arrFeatures = raster.read(featureFile, bands='all')\n",
    "arrFeatures = arrFeatures.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(arrFeatures.shape[0]):\n",
    "    bandMin = arrFeatures[i][:][:].min()\n",
    "    bandMax = arrFeatures[i][:][:].max()\n",
    "    bandRange = bandMax-bandMin\n",
    "    for j in range(arrFeatures.shape[1]):\n",
    "        for k in range(arrFeatures.shape[2]):\n",
    "            arrFeatures[i][j][k] = (arrFeatures[i][j][k]-bandMin)/bandRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53574908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc11edd6",
   "metadata": {
    "id": "sjuSXatfPv40"
   },
   "outputs": [],
   "source": [
    "# Creating chips using pyrsgis\n",
    "features = imageChipsFromArray(arrFeatures, x_size=7, y_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31822d39",
   "metadata": {
    "id": "b_rFLEXYPv40"
   },
   "outputs": [],
   "source": [
    "# Reading and reshaping the label file\n",
    "dsLabels, arrLabels = raster.read(labelFile)\n",
    "arrLabels[arrLabels==255] = 0\n",
    "arrLabels = arrLabels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb81de",
   "metadata": {
    "id": "IndJ6o-IPv40"
   },
   "outputs": [],
   "source": [
    "# Separating and balancing the classes\n",
    "features = features[arrLabels!=0]\n",
    "labels = arrLabels[arrLabels!=0]\n",
    "\n",
    "# Defining the function to split features and labels\n",
    "def train_test_split(features, labels, trainProp=0.70):\n",
    "    dataSize = features.shape[0]\n",
    "    sliceIndex = int(dataSize*trainProp)\n",
    "    randIndex = np.arange(dataSize)\n",
    "    random.shuffle(randIndex)\n",
    "    train_x = features[[randIndex[:sliceIndex]], :, :, :][0]\n",
    "    test_x = features[[randIndex[sliceIndex:]], :, :, :][0]\n",
    "    train_y = labels[randIndex[:sliceIndex]]\n",
    "    test_y = labels[randIndex[sliceIndex:]]\n",
    "    return(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857b6ec",
   "metadata": {
    "id": "1GvGNFNiPv40"
   },
   "outputs": [],
   "source": [
    "# Calling the function to split the data\n",
    "train_x, train_y, test_x, test_y = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d8a27",
   "metadata": {
    "id": "nMlffbOHPv40"
   },
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "# !pip install tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de313ab",
   "metadata": {
    "id": "bIHjjXgJPv41",
    "outputId": "23e15e9b-d2c8-4d73-b66a-565fd611cbac"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=1, padding='valid', activation='relu', input_shape=(train_x.shape[1], train_x.shape[2], train_x.shape[3])))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Conv2D(48, kernel_size=1, padding='valid', activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034d0ed",
   "metadata": {
    "id": "W8WOvFOJPv41",
    "outputId": "ba75c9e8-21f4-40fb-ebc7-20f7848716cb"
   },
   "outputs": [],
   "source": [
    "# Running the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c254fc9",
   "metadata": {
    "id": "UBn7bFEYPv41"
   },
   "outputs": [],
   "source": [
    "# Loading and normalizing a new multispectral image\n",
    "dsPre, featuresPre = raster.read(r\"D:\\KULIAH\\Makan Bang\\Argopuro\\10. ML\\Code\\CNN\\Dataset\\Virtual Raster.tif\")\n",
    "featuresPre = featuresPre.astype(float)\n",
    "\n",
    "for i in range(featuresPre.shape[0]):\n",
    "    bandMinPre = featuresPre[i][:][:].min()\n",
    "    bandMaxPre = featuresPre[i][:][:].max()\n",
    "    bandRangePre = bandMaxPre-bandMinPre\n",
    "    for j in range(featuresPre.shape[1]):\n",
    "        for k in range(featuresPre.shape[2]):\n",
    "            featuresPre[i][j][k] = (featuresPre[i][j][k]-bandMinPre)/bandRangePre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbee412",
   "metadata": {
    "id": "xLes3vOmPv41"
   },
   "outputs": [],
   "source": [
    "# Generating image chips from the array\n",
    "new_features = imageChipsFromArray(featuresPre, x_size=7, y_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0546f1",
   "metadata": {
    "id": "DDgGvxsJPv41"
   },
   "outputs": [],
   "source": [
    "# Predicting new data and exporting the probability raster\n",
    "newPredicted = model.predict(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98c1c5",
   "metadata": {
    "id": "qSrDN_13Pv41"
   },
   "outputs": [],
   "source": [
    "prediction = np.reshape(newPredicted.argmax(axis=1), (dsPre.RasterYSize, dsPre.RasterXSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b773ad",
   "metadata": {
    "id": "FjrY4Tc2Pv42"
   },
   "outputs": [],
   "source": [
    "outFile = r'D:\\KULIAH\\Makan Bang\\Argopuro\\11. Hasil\\CNN\\CNN.tif'\n",
    "raster.export(prediction, dsPre, filename=outFile, dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36678770",
   "metadata": {
    "id": "YFWcf1fzPv42",
    "outputId": "0bba8815-431a-4c30-fe5c-0600f8a4c4cc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cnn_map \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(cnn_map\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_map = prediction\n",
    "print(cnn_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a5793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total samples\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(cnn_map, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb75d2e",
   "metadata": {
    "id": "zE44ok1ePv42"
   },
   "source": [
    "# CM-CNN-Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e132282",
   "metadata": {
    "id": "F3VvwrKBPv43"
   },
   "outputs": [],
   "source": [
    "# Predicting for test data \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "yTestPredicted = model.predict(test_x)\n",
    "y_score = yTestPredicted[:, 1:yTestPredicted.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652584a",
   "metadata": {
    "id": "EnaJG4piPv43"
   },
   "outputs": [],
   "source": [
    "# Predicting for test data \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "yTestPredicted = model.predict(test_x)\n",
    "y_score = yTestPredicted[:, 1:yTestPredicted.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a708ca",
   "metadata": {
    "id": "XKs6HZEUPv43"
   },
   "outputs": [],
   "source": [
    "# Calculating and displaying error metrics\n",
    "yTestPredicted = (yTestPredicted>0.5).astype(int)\n",
    "\n",
    "cMatrix = confusion_matrix(test_y, yTestPredicted.argmax(axis=1))\n",
    "pScore = precision_score(test_y, yTestPredicted.argmax(axis=1), average='micro')\n",
    "rScore = recall_score(test_y, yTestPredicted.argmax(axis=1), average='micro')\n",
    "fscore = f1_score(test_y, yTestPredicted.argmax(axis=1), average='micro')\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cMatrix)\n",
    "print(\"\\nP-Score: %.3f, R-Score: %.3f, F-Score: %.3f\" % (pScore, rScore, fscore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a1321",
   "metadata": {
    "id": "Uc_8XpYePv42",
    "outputId": "dc9c6142-8bfe-42fe-d85b-2dd603d6538f"
   },
   "outputs": [],
   "source": [
    "# CM-CNN-Accuracy Assessment\n",
    "\n",
    "# Predicting for test data \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "yTestPredicted = model.predict(test_x)\n",
    "y_score = yTestPredicted[:, 1:yTestPredicted.shape[1]]\n",
    "\n",
    "# Predicting for test data \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "yTestPredicted = model.predict(test_x)\n",
    "y_score = yTestPredicted[:, 1:yTestPredicted.shape[1]]\n",
    "\n",
    "# Calculating and displaying error metrics\n",
    "yTestPredicted = (yTestPredicted>0.5).astype(int)\n",
    "\n",
    "cMatrix = confusion_matrix(test_y, yTestPredicted.argmax(axis=1))\n",
    "pScore = precision_score(test_y, yTestPredicted.argmax(axis=1), average='micro')\n",
    "rScore = recall_score(test_y, yTestPredicted.argmax(axis=1), average='micro')\n",
    "fscore = f1_score(test_y, yTestPredicted.argmax(axis=1), average='micro')\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cMatrix)\n",
    "print(\"\\nP-Score: %.3f, R-Score: %.3f, F-Score: %.3f\" % (pScore, rScore, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a31ac5c",
   "metadata": {
    "id": "XFLiqGQJPv47"
   },
   "source": [
    "# ROC - CNN - Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed9d92",
   "metadata": {
    "id": "7RIR6VsyPv47"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7449ad",
   "metadata": {
    "id": "nn1k5sBEPv47"
   },
   "outputs": [],
   "source": [
    "yTestPredicted = model.predict(test_x)\n",
    "y_score = yTestPredicted[:, 1:yTestPredicted.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854bcdac",
   "metadata": {
    "id": "K_Cubmv-Pv48"
   },
   "outputs": [],
   "source": [
    "# Computing ROC parameters for each class\n",
    "n_classes = 9\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fda53",
   "metadata": {
    "id": "pD5f_u5JPv48"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "test_y = label_binarize(test_y, classes=list(range(1, n_classes+1)))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_y[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e06f8c",
   "metadata": {
    "id": "7CISaQcfPv48"
   },
   "outputs": [],
   "source": [
    "# Computing micro-average ROC parameters\n",
    "fpr['micro'], tpr['micro'], _ = roc_curve(test_y.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7408c",
   "metadata": {
    "id": "3y1AbouuPv48"
   },
   "outputs": [],
   "source": [
    "# Computing macro-average ROC parameters\n",
    "# First aggregating all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6d976",
   "metadata": {
    "id": "GecSkelWPv48"
   },
   "outputs": [],
   "source": [
    "# Then interpolating all ROC curves at the points obtained from the line above\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196a439",
   "metadata": {
    "id": "IzWXbGUsPv48"
   },
   "outputs": [],
   "source": [
    "# Finally averaging and computing AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e082cd",
   "metadata": {
    "id": "NmDdtD-yPv48",
    "outputId": "ebb3d761-d907-4e13-80be-f8879a93d3d0"
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32897a48",
   "metadata": {
    "id": "lw3YgXTKPv48",
    "outputId": "d58fee90-dc86-48dd-b337-a842cb490160"
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2807ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186f3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470dd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f089c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1cf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591719b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341cedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
